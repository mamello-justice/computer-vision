{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computer Vision\n",
    "\n",
    "## Assignment - UNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install segmentation_models --quiet\n",
    "%pip install comet_ml --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comet Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from comet_ml import Experiment\n",
    "\n",
    "experiment = Experiment(project_name = \"cv-deep\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import time\n",
    "import os\n",
    "from os import path\n",
    "\n",
    "from natsort import natsorted\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import imageio\n",
    "import numpy as np\n",
    "from skimage import img_as_float32\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import callbacks\n",
    "from keras.models import load_model\n",
    "from segmentation_models import Unet\n",
    "\n",
    "\n",
    "print(f\"numpy=={np.__version__}\")\n",
    "print(f\"tensorflow=={tf.__version__}\")\n",
    "print(f\"keras=={keras.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images(input_dir, height, width):\n",
    "    image_dir = path.join(input_dir, f'images-{width}x{height}')\n",
    "    image_paths = natsorted(glob(f'{image_dir}/*.png'))\n",
    "    raw_images = np.array([\n",
    "        img_as_float32(imageio.imread(path))\n",
    "        for path in tqdm(image_paths, 'Reading in images')\n",
    "    ])\n",
    "\n",
    "    mask_dir = path.join(input_dir, f'masks-{width}x{height}')\n",
    "    mask_paths = natsorted(glob(f'{mask_dir}/*.png'))\n",
    "    raw_masks = np.array([\n",
    "        img_as_float32(imageio.imread(path))\n",
    "        for path in tqdm(mask_paths, 'Reading in masks')\n",
    "    ])\n",
    "\n",
    "    return raw_images, raw_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(raw_images, raw_masks):\n",
    "    N = len(raw_images)\n",
    "    indices = np.random.permutation(N)\n",
    "\n",
    "    train_end = int(0.7*N) + 1\n",
    "    train_indices = indices[:train_end]\n",
    "\n",
    "    validation_end = train_end + int(0.15*N)\n",
    "    validation_indices = indices[train_end:validation_end]\n",
    "\n",
    "    test_indices = indices[validation_end:]\n",
    "\n",
    "    return (raw_images[train_indices], raw_masks[train_indices]),\\\n",
    "        (raw_images[validation_indices], raw_masks[validation_indices]),\\\n",
    "        (raw_images[test_indices], raw_masks[test_indices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_images(raw_images, raw_masks):\n",
    "    images = raw_images\n",
    "    masks = raw_masks\n",
    "    \n",
    "    if len(masks.shape) == 3:\n",
    "        masks = np.expand_dims(masks, axis=3)\n",
    "        \n",
    "    return images, masks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BACKBONE = 'vgg16'\n",
    "\n",
    "assets_dir = './assets'\n",
    "data_dir = './data'\n",
    "\n",
    "default_input_size = [768, 1024]\n",
    "default_input_dir = path.join(\n",
    "    assets_dir,\n",
    "    f'puzzle_corners_{default_input_size[1]}x{default_input_size[0]}')\n",
    "\n",
    "time_now = int(time.time())\n",
    "\n",
    "default_cp_path = path.join(data_dir, str(time_now), 'cp.ckpt')\n",
    "default_model_path = path.join(data_dir, str(time_now), 'model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'augmented': True,\n",
    "    'batch_size': 2,\n",
    "    'epochs': 2,\n",
    "    'input_size': default_input_size,\n",
    "}\n",
    "\n",
    "experiment.log_parameters(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_args():\n",
    "    return {\n",
    "        'cp_path': default_cp_path,\n",
    "        'input_dir': default_input_dir,\n",
    "        'model_path': default_model_path,\n",
    "        'update_model': None,\n",
    "        'cpu': True\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = setup_args()\n",
    "\n",
    "use_cpu = args['cpu']\n",
    "if use_cpu:\n",
    "    os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "\n",
    "augmented = params['augmented']\n",
    "batch_size = params['batch_size']\n",
    "epochs = params['epochs']\n",
    "input_size = params['input_size']\n",
    "\n",
    "cp_path = args['cp_path']\n",
    "input_dir = args['input_dir']\n",
    "model_path = args['model_path']\n",
    "update_model = args['update_model']\n",
    "\n",
    "height, width = input_size\n",
    "\n",
    "raw_images, raw_masks = load_images(input_dir, height, width)\n",
    "\n",
    "images, masks = preprocess_images(raw_images, raw_masks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_x, train_y), (val_x, val_y), (test_x, test_y) =\\\n",
    "    split_data(raw_images, masks)\n",
    "    \n",
    "experiment.log_dataset_hash(train_x)\n",
    "\n",
    "checkpoint_cb = callbacks.ModelCheckpoint(filepath=cp_path,\n",
    "                                          save_weights_only=True,\n",
    "                                          verbose=1)\n",
    "\n",
    "if update_model and model_path:\n",
    "    model = load_model(model_path)\n",
    "else:\n",
    "    model = Unet(BACKBONE,\n",
    "                 encoder_weights='imagenet',\n",
    "                 input_shape=(*input_size, 3))\n",
    "    \n",
    "assert model is not None, \"Could not load model\"\n",
    "\n",
    "model.compile(optimizer='Adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_x, train_y,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          validation_data=(val_x, val_y),\n",
    "          callbacks=[checkpoint_cb])\n",
    "\n",
    "model.save(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comet Commit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment.end()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "14a7046b3493b92b1d842fb1e941b2babd846baed7e15e3a50bd6e259b71f0cc"
  },
  "kernelspec": {
   "display_name": "Python 3.10.7 ('cv_gmm_deep')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
